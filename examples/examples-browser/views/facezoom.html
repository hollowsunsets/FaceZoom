<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <script src="face-api.js"></script>
  <script src="js/commons.js"></script>
  <script src="js/faceDetectionControls.js"></script>
  <link rel="stylesheet" href="styles.css">
  <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/css/bootstrap.min.css" integrity="sha384-ggOyR0iXCbMQv3Xipma34MD+dH/1fQ784/j6cY/iJTQUOhcWr7x9JvoRxT2MZw1T" crossorigin="anonymous">
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/css/materialize.css">
  <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/materialize/0.100.2/js/materialize.min.js"></script>
</head>

<header>
  <h1> Facezoom </h1>
</header>
<section>


    <div style="position: relative" class="margin">
      <video onloadedmetadata="onPlay(this)" id="inputVideo" autoplay muted playsinline></video>
    <canvas id="overlay"></canvas>
    
	<div>
		<div id="zoom_container" class="margin"></div>
		<label for="zoom_container">Facecam</label>
	</div>
    <div id="emotion_container" class="margin">
    <div class="emotion_entry">    <canvas id="a"></canvas><br/>
      <label for="a">Angry</label></div>

    <div class="emotion_entry">    <canvas id="d"></canvas><br/>
      <label for="d">Disgusted</label>
    </div>
    <div class="emotion_entry">    <canvas id="f"></canvas><br/>
      <label for="f">Fearful</label>
    </div>
    <div class="emotion_entry">    <canvas id="h"></canvas> <br/>
      <label for="h">Happy</label>
    </div>
    <div class="emotion_entry">
      <canvas id="n"></canvas> <br/>
      <label for="n">Neutral</label>
    </div>
    <div class="emotion_entry">    <canvas id="sa"></canvas> <br/>
      <label for="sa">Sad</label>
    </div>
    <div class="emotion_entry">    <canvas id="su"></canvas> <br/>
      <label for="su">Surprised</label>
    </div>
    </div>
    

    <!-- mtcnn_controls -->
    <span id="mtcnn_controls">
      <div class="row side-by-side">
        <div class="row">
          <label for="minFaceSize">Minimum Face Size:</label>
          <input disabled value="20" id="minFaceSize" type="text" class="bold">
        </div>
        <button
          class="waves-effect waves-light btn"
          onclick="onDecreaseMinFaceSize()"
        >
          <i class="material-icons left">-</i>
        </button>
        <button
          class="waves-effect waves-light btn"
          onclick="onIncreaseMinFaceSize()"
        >
          <i class="material-icons left">+</i>
        </button>
      </div>
    </span>
    <!-- mtcnn_controls -->

  </section>
  <footer>
  </footer>

  <script>
    let forwardTimes = []
	let isRecording = true;

    function updateTimeStats(timeInMs) {
      forwardTimes = [timeInMs].concat(forwardTimes).slice(0, 30)
      const avgTimeInMs = forwardTimes.reduce((total, t) => total + t) / forwardTimes.length
      $('#time').val(`${Math.round(avgTimeInMs)} ms`)
      $('#fps').val(`${faceapi.round(1000 / avgTimeInMs)}`)
    }
    // angry, disgusted, fearful, happy, neutral, sad, surprised
    var pastEmotions = [false, false, false, false, false, false, false]

    const EMOTION_THRESHOLD = 0.75
    async function onPlay() {
	  if (!isRecording) {
		  return
	  }
      const videoEl = $('#inputVideo').get(0)

      if(videoEl.paused || videoEl.ended || !isFaceDetectionModelLoaded())
        return setTimeout(() => onPlay())


      const options = getFaceDetectorOptions()

      const ts = Date.now()

      const result_array = await faceapi.detectAllFaces(videoEl, options).withFaceExpressions()

      updateTimeStats(Date.now() - ts)

      if (result_array) {
    const canvas_overlay = $('#overlay').get(0)
		const canvas_zoom_container = $('#zoom_container').get(0)
		const dims = faceapi.matchDimensions(canvas_overlay, videoEl, true)
    let i = 0;
	    for (; i < result_array.length; i++) {
		  let result = result_array[i]
		  const resizedResult = faceapi.resizeResults(result, dims)
	      const minConfidence = 0.05
		  faceapi.draw.drawDetections(canvas_overlay, resizedResult)
          faceapi.draw.drawFaceExpressions(canvas_overlay, resizedResult, minConfidence)
		  let canvas_zoom = $('#zoom' + i).get(0)
		  if (!canvas_zoom) {
			  canvas_zoom = document.createElement('canvas')
			  canvas_zoom.classList.add('zoom_entry')
			  canvas_zoom.id = 'zoom' + i
			  canvas_zoom_container.appendChild(canvas_zoom)
		  }
		  const ctx_zoom = canvas_zoom.getContext('2d');
		  const detectionBox = resizedResult.detection.box
		  canvas_zoom.width = detectionBox.width
		  canvas_zoom.height = detectionBox.height
		  ctx_zoom.drawImage(videoEl, detectionBox.x, detectionBox.y, detectionBox.width, detectionBox.height, 0, 0, canvas_zoom.width, canvas_zoom.height)
      if (resizedResult.expressions.angry >= EMOTION_THRESHOLD && !pastEmotions[0]) {
      pastEmotions[0] = true
      let temp = $('#a').get(0)
      temp.width = detectionBox.width
		  temp.height = detectionBox.height
      const temp2 = temp.getContext('2d');
      temp2.drawImage(videoEl, detectionBox.x, detectionBox.y, detectionBox.width, detectionBox.height, 0, 0, temp.width, temp.height)
      } else if (resizedResult.expressions.disgusted >= EMOTION_THRESHOLD && !pastEmotions[1]) {
      pastEmotions[1] = true
      let temp = $('#d').get(0)
      temp.width = detectionBox.width
		  temp.height = detectionBox.height
      const temp2 = temp.getContext('2d');
      temp2.drawImage(videoEl, detectionBox.x, detectionBox.y, detectionBox.width, detectionBox.height, 0, 0, temp.width, temp.height)  
      } else if (resizedResult.expressions.fearful >= EMOTION_THRESHOLD && !pastEmotions[2]) {
      pastEmotions[2] = true
      let temp = $('#f').get(0)
      temp.width = detectionBox.width
		  temp.height = detectionBox.height
      const temp2 = temp.getContext('2d');
      temp2.drawImage(videoEl, detectionBox.x, detectionBox.y, detectionBox.width, detectionBox.height, 0, 0, temp.width, temp.height)  
      } else if (resizedResult.expressions.happy >= EMOTION_THRESHOLD && !pastEmotions[3]) {
      pastEmotions[3] = true
      let temp = $('#h').get(0)
      temp.width = detectionBox.width
		  temp.height = detectionBox.height
      const temp2 = temp.getContext('2d');
      temp2.drawImage(videoEl, detectionBox.x, detectionBox.y, detectionBox.width, detectionBox.height, 0, 0, temp.width, temp.height)  
      } else if (resizedResult.expressions.neutral >= EMOTION_THRESHOLD && !pastEmotions[4]) {
      pastEmotions[4] = true
      let temp = $('#n').get(0)
      temp.width = detectionBox.width
		  temp.height = detectionBox.height
      const temp2 = temp.getContext('2d');
      temp2.drawImage(videoEl, detectionBox.x, detectionBox.y, detectionBox.width, detectionBox.height, 0, 0, temp.width, temp.height)  
      } else if (resizedResult.expressions.sad >= EMOTION_THRESHOLD && !pastEmotions[5]) {
      pastEmotions[5] = true
      let temp = $('#sa').get(0)
      temp.width = detectionBox.width
		  temp.height = detectionBox.height
      const temp2 = temp.getContext('2d');
      temp2.drawImage(videoEl, detectionBox.x, detectionBox.y, detectionBox.width, detectionBox.height, 0, 0, temp.width, temp.height)  
      } else if (resizedResult.expressions.surprised >= EMOTION_THRESHOLD && !pastEmotions[6]) {
      pastEmotions[6] = true
      let temp = $('#su').get(0)
      temp.width = detectionBox.width
		  temp.height = detectionBox.height
      const temp2 = temp.getContext('2d');
      temp2.drawImage(videoEl, detectionBox.x, detectionBox.y, detectionBox.width, detectionBox.height, 0, 0, temp.width, temp.height)  
      }
		}
    let old_zoom = $('#zoom' + i).get(0)
  while (old_zoom && old_zoom.parentElement) {
      old_zoom.parentElement.removeChild(old_zoom)
      i++
    }
      }
    
      setTimeout(() => onPlay())
    }


    async function run() {
      // load face detection model
      await changeFaceDetector(TINY_FACE_DETECTOR)
      await faceapi.loadFaceExpressionModel('/')
      changeInputSize(224)

      // try to access users webcam and stream the images
      // to the video element
      const stream = await navigator.mediaDevices.getUserMedia({ video: {} })
      const videoEl = $('#inputVideo').get(0)
      videoEl.srcObject = stream
	  $('#overlay').get(0).addEventListener('click', (event) => {
		  isRecording = !isRecording;
		  if (isRecording) {
			  videoEl.play()
			  setTimeout(() => onPlay())
		  } else {
			  videoEl.pause()
		  }
	  })
    }

    function updateResults() {}

    $(document).ready(function() {
      // renderNavBar('#navbar', 'facezoom')
      initFaceDetectionControls()
      run()
    })
  </script>
   <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.14.7/umd/popper.min.js" integrity="sha384-UO2eT0CpHqdSJQ6hJty5KVphtPhzWj9WO1clHTMGa3JDZwrnQq4sF86dIHNDz0W1" crossorigin="anonymous"></script>
   <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.3.1/js/bootstrap.min.js" integrity="sha384-JjSmVgyd0p3pXB1rRibZUAYoIIy6OrQ6VrjIEaFf/nJGzIxFDsf4x0xIM+B07jRM" crossorigin="anonymous"></script>
 </body>
</body>
</html>
